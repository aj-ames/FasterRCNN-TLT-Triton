# FasterRCNN with TLT 3.0 and Triton Inference Server

## 1. TLT Setup

The instructions to install dependencies are in `SETUP.md`. Alternatively, you can follow [https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/index.html](https://docs.nvidia.com/metropolis/TLT/tlt-user-guide/index.html).

## 2. Training FasterRCNN with TLT 3.0

You can run `faster_rcnn/faster_rcnn.ipynb` for regular training and `faster_rcnn/faster_rcnn_qat.ipynb` for Quantization Aware Training.

Instructions are in `TRAIN.md`